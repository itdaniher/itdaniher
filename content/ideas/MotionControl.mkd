### "standard" solution, implemented by makerbot and RAMPS derived hardware systems

* hardware
 * FT232 -> ATmega2560 or compatible -> A4988 stepper drivers
* software
 * CAD -> STL -> GCode -> <magic> -> stepper driver step/dir

Where <magic> is either....

* makerbot compatible
 * ProtocolDocumentation.hh
 * Commands.hh
 *  Packet.cc
* reprap compatible
*  Sprinter.pde
*  similar to grbl - streamed ASCII processed by a switch/case

### host software

* Replicator G ships with “reprap.xml” which allows use of streamed-ascii hardware
*  Printrun - pure Python CLI for streamed-GCode hardware

* each line of g-code contains an atomic motion command and thus can be processed independently
* perfectly functional for recorded motions, but not for manual control
* each section of time would need to be converted to a gcode command (relative movement) and sent down the pipe, causing significant latency from all steps
* rounding errors will accumulate
* why’s streamed ascii so popular?
 * impractical to stream step/dir commands
 *  printing a large circle would require hundreds of bytes of information - small pipe would mean each operation would take dozens of ms to transfer and it’s not easy to buffer that much data in memory-limited systems
 *  stays human readable


### How could we make existing solutions work?

* Printrun is a solid abstraction layer that we could possibly adapt to be a general purpose userspace motion control platform, but aforementioned gcode synthesis problems would still have to be resolved
* firmware-level hacks replacing CDC/ACM serial port with control / bulk requests on teensylu-style system


#### What might something different look like?

* programmable logic paired with a small ARM/Linux computer such as the r’pi or beaglebone


#### why?

* centralize all processing, from CAD to step/direction, in a userspace script
 *  this would allow intimate control of exact real-world behavior, facilitate interesting modeling exercises, and allow for rapid prototyping of novel control schemes (multi-bezier?)
 * allow userspace applications soft-realtime motion control, facilitating humantime interaction with multiaxis robotics with lower latency than a gcode synthesis approach might allow
* reduce the amount of compiled code and hard logic between computer and motors
* facilitate “applianceization” of 3d printer technology
* because most other solutions suck and this would be awesome.


#### how?

* tether a CPLD to an ARM processor over a simple high-speed serial (or parallel) bus
* provide CPLD with sufficient memory to buffer a large number of operations, allowing for deterministic, low-latency execution of a series of planned moves
* consider implementing stepper control routines in verilog, and pairing CPLD with a quad-half-H as a costsaving mechanism - see Xilinx app note 940 for an implementation of this concept
 * microstepping would be nontrivial to implement sans lookup table or easy way to build a sine wave
 * microstepping might not be needed for PnP work, given the large gear ratio granted by the belt
 

XC2C64A provides 64MCells and 33IO. runs off 1.8v, takes 3.3V for IO

A4988 provides dual h-bridge, microstepping logic, and current control chopper

TB6612 provides dual h-bridge with PWM for each
